{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repo Rover Demo\n",
    "### From Paper Title to Running Code in 60 Seconds\n",
    "\n",
    "This notebook demonstrates the complete Repo Rover pipeline:\n",
    "1. Find research paper on ArXiv\n",
    "2. Discover GitHub repository\n",
    "3. Index code with Vectara RAG\n",
    "4. Answer questions using Gemini\n",
    "5. Generate minimal working examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab)\n",
    "!pip install -q uagents google-generativeai arxiv GitPython rich python-dotenv requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (if running in Colab)\n",
    "import os\n",
    "if not os.path.exists('repo-rover'):\n",
    "    !git clone https://github.com/YOUR_USERNAME/repo-rover.git\n",
    "    %cd repo-rover/src\n",
    "else:\n",
    "    %cd repo-rover/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API keys (REQUIRED)\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['GEMINI_API_KEY'] = getpass('Enter Gemini API Key: ')\n",
    "os.environ['VECTARA_CUSTOMER_ID'] = getpass('Enter Vectara Customer ID: ')\n",
    "os.environ['VECTARA_API_KEY'] = getpass('Enter Vectara API Key: ')\n",
    "os.environ['VECTARA_CORPUS_ID'] = getpass('Enter Vectara Corpus ID: ')\n",
    "os.environ['SKIP_CONFIG_VALIDATION'] = 'true'\n",
    "\n",
    "print(\"✓ API keys configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Repo Rover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import RepoRover\n",
    "\n",
    "# Create instance\n",
    "rover = RepoRover()\n",
    "print(\"✓ Repo Rover initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Analyze \"Attention Is All You Need\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the paper\n",
    "paper_query = \"Attention Is All You Need\"\n",
    "success = rover.analyze_paper(paper_query)\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✓ Analysis complete!\")\n",
    "    print(f\"Paper: {rover.paper_info['title']}\")\n",
    "    print(f\"ArXiv ID: {rover.paper_info['arxiv_id']}\")\n",
    "    print(f\"Authors: {', '.join(rover.paper_info['authors'][:3])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View suggested questions\n",
    "suggestions = rover.pipeline.suggest_questions()\n",
    "print(\"Suggested questions:\")\n",
    "for i, q in enumerate(suggestions, 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = \"Show me the multi-head attention implementation\"\n",
    "response = rover.query(question)\n",
    "\n",
    "print(\"\\nAnswer:\")\n",
    "print(response['answer'])\n",
    "print(f\"\\nConfidence: {response['confidence']}\")\n",
    "print(f\"Based on {response['num_sources']} code sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another question\n",
    "question2 = \"Explain positional encoding\"\n",
    "response2 = rover.query(question2)\n",
    "\n",
    "print(\"\\nAnswer:\")\n",
    "print(response2['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: Generate Minimal Working Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate MWE for MultiHeadAttention\n",
    "mwe_code = rover.generate_mwe(\"MultiHeadAttention\")\n",
    "\n",
    "print(\"Generated Minimal Working Example:\")\n",
    "print(\"=\" * 60)\n",
    "print(mwe_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to run the generated MWE\n",
    "try:\n",
    "    exec(mwe_code)\n",
    "    print(\"\\n✓ MWE executed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nNote: MWE may need additional dependencies: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: Explore Different Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a different paper (BERT)\n",
    "rover2 = RepoRover()\n",
    "success = rover2.analyze_paper(\"BERT: Pre-training of Deep Bidirectional Transformers\")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✓ BERT paper analyzed!\")\n",
    "    \n",
    "    # Ask a question\n",
    "    response = rover2.query(\"How is masked language modeling implemented?\")\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showed:\n",
    "1. ✅ Automatic paper discovery from ArXiv\n",
    "2. ✅ GitHub repository finding via Papers with Code\n",
    "3. ✅ Semantic code search with Vectara RAG\n",
    "4. ✅ Intelligent Q&A with Gemini 2.0 Flash\n",
    "5. ✅ Minimal working example generation\n",
    "\n",
    "**Total time: < 3 minutes**\n",
    "\n",
    "### Partner Technologies Used\n",
    "- **Google Gemini 2.0 Flash**: Long-context understanding (2M tokens)\n",
    "- **Vectara**: Semantic code search and RAG\n",
    "- **Fetch.ai**: Agent deployment (see agent.py)\n",
    "- **Papers with Code**: Repository discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Deploy as Fetch.ai agent: `python agent.py`\n",
    "2. Try more papers and questions\n",
    "3. Customize concept mapping\n",
    "4. Add support for more file types\n",
    "\n",
    "---\n",
    "**Repo Rover** - From paper title to running code in 60 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
